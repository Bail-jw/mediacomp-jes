\chapter{Introduction to Computer Science and Media Computation}

\begin{exercises}

\begin{ex}
This question is relatively self-explanitory. 
\end{ex}

\begin{ex} 
ASCII codes are designed so that a capital letter is the letter's order in
the alphabet plus 64. For example, a capital A would be 65 because it's the
first letter in the alphabet + 64. B would be 66, C would be 67, etc. For
lowercase numbers, the offset is 96 instead of 64. A lowercase a would be
97, b would be 98, etc. The reason these offsets are used is because it
optimizes readibility in binary and hexadecimal notation.
\end{ex}

\begin{ex}
Unicode uses two bytes to encode each character, therefore rather than 256
possibilities, there are 65536 possible characters. Unicode supports all
the characters that are included in the standard ASCII set along with
characters from many other languages including arabic and odd math symbols.
\end{ex}

\begin{ex}
If each pixel is 3 bytes, then a 640 by 480 picture would require 640 × 480
× 3 bytes = 921,600 bytes = 900 Kilobytes.  For a 1024 by 768 picture, that
figure balloons up to 2,359,296 bytes = 2.25 Megabytes. (1 kilobyte = 1024
bytes, not 1000 bytes. 1 megabyte = 1024 * 1024 bytes, not 1 million. A
common CS misconception.)
\end{ex}



\begin{ex}
1 bit can represent two unique values: 1 or 0. If you have 2 bits, then you
can represent $2^2$  possible values. Therefore, if you have 8 bits (which is
how many bits are in a byte) then you can represent $2^8$ possible numbers
(which is 256). If you have 2 bytes, then you have 16 bits. $2^{16}$ =
65,536 possibilities. If you have 4 bytes then you have 32 bits. $2^{32}$ =
4,294,967,296 possible values.
\end{ex}


\begin{ex}

\end{ex}

\begin{ex}
\end{ex}

\begin{ex}
\end{ex}

\begin{ex}
\end{ex}

\end{exercises}

